{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MicroprocessorX069/Generalized-pix2pix-GAN-API/blob/master/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kj_ispRjYY3O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class generator(nn.Module):\n",
        "    # initializers\n",
        "    def __init__(self, d=64):\n",
        "        super(generator, self).__init__()\n",
        "        # Unet encoder\n",
        "        self.conv1 = nn.Conv2d(3, d, 4, 2, 1)\n",
        "        self.conv2 = nn.Conv2d(d, d * 2, 4, 2, 1)\n",
        "        self.conv2_bn = nn.BatchNorm2d(d * 2)\n",
        "        self.conv3 = nn.Conv2d(d * 2, d * 4, 4, 2, 1)\n",
        "        self.conv3_bn = nn.BatchNorm2d(d * 4)\n",
        "        self.conv4 = nn.Conv2d(d * 4, d * 8, 4, 2, 1)\n",
        "        self.conv4_bn = nn.BatchNorm2d(d * 8)\n",
        "        self.conv5 = nn.Conv2d(d * 8, d * 8, 4, 2, 1)\n",
        "        self.conv5_bn = nn.BatchNorm2d(d * 8)\n",
        "        self.conv6 = nn.Conv2d(d * 8, d * 8, 4, 2, 1)\n",
        "        self.conv6_bn = nn.BatchNorm2d(d * 8)\n",
        "        self.conv7 = nn.Conv2d(d * 8, d * 8, 4, 2, 1)\n",
        "        self.conv7_bn = nn.BatchNorm2d(d * 8)\n",
        "        self.conv8 = nn.Conv2d(d * 8, d * 8, 4, 2, 1)\n",
        "        #self.conv8_bn = nn.BatchNorm2d(d * 8)\n",
        "\n",
        "        # Unet decoder\n",
        "        self.deconv1 = nn.ConvTranspose2d(d * 8, d * 8, 4, 2, 1)\n",
        "        self.deconv1_bn = nn.BatchNorm2d(d * 8)\n",
        "        self.deconv2 = nn.ConvTranspose2d(d * 8 * 2, d * 8, 4, 2, 1)\n",
        "        self.deconv2_bn = nn.BatchNorm2d(d * 8)\n",
        "        self.deconv3 = nn.ConvTranspose2d(d * 8 * 2, d * 8, 4, 2, 1)\n",
        "        self.deconv3_bn = nn.BatchNorm2d(d * 8)\n",
        "        self.deconv4 = nn.ConvTranspose2d(d * 8 * 2, d * 8, 4, 2, 1)\n",
        "        self.deconv4_bn = nn.BatchNorm2d(d * 8)\n",
        "        self.deconv5 = nn.ConvTranspose2d(d * 8 * 2, d * 4, 4, 2, 1)\n",
        "        self.deconv5_bn = nn.BatchNorm2d(d * 4)\n",
        "        self.deconv6 = nn.ConvTranspose2d(d * 4 * 2, d * 2, 4, 2, 1)\n",
        "        self.deconv6_bn = nn.BatchNorm2d(d * 2)\n",
        "        self.deconv7 = nn.ConvTranspose2d(d * 2 * 2, d, 4, 2, 1)\n",
        "        self.deconv7_bn = nn.BatchNorm2d(d)\n",
        "        self.deconv8 = nn.ConvTranspose2d(d * 2, 3, 4, 2, 1)\n",
        "\n",
        "    # weight_init\n",
        "    def weight_init(self, mean, std):\n",
        "        for m in self._modules:\n",
        "            normal_init(self._modules[m], mean, std)\n",
        "\n",
        "    # forward method\n",
        "    def forward(self, input):\n",
        "        #print(\"Input to gen: \", input.size())\n",
        "        e1 = self.conv1(input)\n",
        "        #print(\"Size after e1: \", e1.size())\n",
        "        e2 = self.conv2_bn(self.conv2(F.leaky_relu(e1, 0.2)))\n",
        "        e3 = self.conv3_bn(self.conv3(F.leaky_relu(e2, 0.2)))\n",
        "        e4 = self.conv4_bn(self.conv4(F.leaky_relu(e3, 0.2)))\n",
        "        e5 = self.conv5_bn(self.conv5(F.leaky_relu(e4, 0.2)))\n",
        "        e6 = self.conv6_bn(self.conv6(F.leaky_relu(e5, 0.2)))\n",
        "        e7 = self.conv7_bn(self.conv7(F.leaky_relu(e6, 0.2)))\n",
        "        e8 = self.conv8(F.leaky_relu(e7, 0.2))\n",
        "        #e8 = self.conv8_bn(self.conv8(F.leaky_relu(e7, 0.2)))\n",
        "        d1 = F.dropout(self.deconv1_bn(self.deconv1(F.relu(e8))), 0.5, training=True)\n",
        "        d1 = torch.cat([d1, e7], 1)\n",
        "        d2 = F.dropout(self.deconv2_bn(self.deconv2(F.relu(d1))), 0.5, training=True)\n",
        "        d2 = torch.cat([d2, e6], 1)\n",
        "        d3 = F.dropout(self.deconv3_bn(self.deconv3(F.relu(d2))), 0.5, training=True)\n",
        "        d3 = torch.cat([d3, e5], 1)\n",
        "        d4 = self.deconv4_bn(self.deconv4(F.relu(d3)))\n",
        "        d4 = F.dropout(self.deconv4_bn(self.deconv4(F.relu(d3))), 0.5)\n",
        "        d4 = torch.cat([d4, e4], 1)\n",
        "        d5 = self.deconv5_bn(self.deconv5(F.relu(d4)))\n",
        "        d5 = torch.cat([d5, e3], 1)\n",
        "        d6 = self.deconv6_bn(self.deconv6(F.relu(d5)))\n",
        "        d6 = torch.cat([d6, e2], 1)\n",
        "        d7 = self.deconv7_bn(self.deconv7(F.relu(d6)))\n",
        "        d7 = torch.cat([d7, e1], 1)\n",
        "        d8 = self.deconv8(F.relu(d7))\n",
        "        o = torch.tanh(d8)\n",
        "\n",
        "        return o\n",
        "\n",
        "class discriminator(nn.Module):\n",
        "    # initializers\n",
        "    def __init__(self, d=64):\n",
        "        super(discriminator, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(6, d, 4, 2, 1)\n",
        "        self.conv2 = nn.Conv2d(d, d * 2, 4, 2, 1)\n",
        "        self.conv2_bn = nn.BatchNorm2d(d * 2)\n",
        "        self.conv3 = nn.Conv2d(d * 2, d * 4, 4, 2, 1)\n",
        "        self.conv3_bn = nn.BatchNorm2d(d * 4)\n",
        "        self.conv4 = nn.Conv2d(d * 4, d * 8, 4, 2, 1)\n",
        "        self.conv4_bn = nn.BatchNorm2d(d * 8)\n",
        "        self.conv5 = nn.Conv2d(d * 8, 1, 4, 2, 1)\n",
        "\n",
        "    # weight_init\n",
        "    def weight_init(self, mean, std):\n",
        "        for m in self._modules:\n",
        "            normal_init(self._modules[m], mean, std)\n",
        "\n",
        "    # forward method\n",
        "    def forward(self, input, label):\n",
        "        x = torch.cat([input, label], 1)\n",
        "        #print(\"Discrim size input cat: \", x.size())\n",
        "        x = F.leaky_relu(self.conv1(x), 0.2)\n",
        "        x = F.leaky_relu(self.conv2_bn(self.conv2(x)), 0.2)\n",
        "        x = F.leaky_relu(self.conv3_bn(self.conv3(x)), 0.2)\n",
        "        x = F.leaky_relu(self.conv4_bn(self.conv4(x)), 0.2)\n",
        "        x = torch.sigmoid(self.conv5(x))\n",
        "\n",
        "        return x\n",
        "\n",
        "def normal_init(m, mean, std):\n",
        "    if isinstance(m, nn.ConvTranspose2d) or isinstance(m, nn.Conv2d):\n",
        "        m.weight.data.normal_(mean, std)\n",
        "        m.bias.data.zero_()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}